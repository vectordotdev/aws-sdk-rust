// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.

/// <p>A structure that contains the configuration settings for an Amazon Transcribe processor.</p>
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::fmt::Debug)]
pub struct AmazonTranscribeProcessorConfiguration {
    /// <p>The language code that represents the language spoken in your audio.</p>
    /// <p>If you're unsure of the language spoken in your audio, consider using <code>IdentifyLanguage</code> to enable automatic language identification.</p>
    /// <p>For a list of languages that real-time Call Analytics supports, see the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages table</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub language_code: ::std::option::Option<crate::types::CallAnalyticsLanguageCode>,
    /// <p>The name of the custom vocabulary that you specified in your Call Analytics request.</p>
    /// <p>Length Constraints: Minimum length of 1. Maximum length of 200.</p>
    pub vocabulary_name: ::std::option::Option<::std::string::String>,
    /// <p>The name of the custom vocabulary filter that you specified in your Call Analytics request.</p>
    /// <p>Length Constraints: Minimum length of 1. Maximum length of 200.</p>
    pub vocabulary_filter_name: ::std::option::Option<::std::string::String>,
    /// <p>The vocabulary filtering method used in your Call Analytics transcription.</p>
    pub vocabulary_filter_method: ::std::option::Option<crate::types::VocabularyFilterMethod>,
    /// <p>Enables speaker partitioning (diarization) in your transcription output. Speaker partitioning labels the speech from individual speakers in your media file.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/diarization.html">Partitioning speakers (diarization)</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub show_speaker_label: bool,
    /// <p>Enables partial result stabilization for your transcription. Partial result stabilization can reduce latency in your output, but may impact accuracy.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html#streaming-partial-result-stabilization">Partial-result stabilization</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub enable_partial_results_stabilization: bool,
    /// <p>The level of stability to use when you enable partial results stabilization (<code>EnablePartialResultsStabilization</code>).</p>
    /// <p>Low stability provides the highest accuracy. High stability transcribes faster, but with slightly lower accuracy.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html#streaming-partial-result-stabilization">Partial-result stabilization</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub partial_results_stability: ::std::option::Option<crate::types::PartialResultsStability>,
    /// <p>Labels all personally identifiable information (PII) identified in your transcript.</p>
    /// <p>Content identification is performed at the segment level; PII specified in <code>PiiEntityTypes</code> is flagged upon complete transcription of an audio segment.</p>
    /// <p>You can’t set <code>ContentIdentificationType</code> and <code>ContentRedactionType</code> in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction.html">Redacting or identifying personally identifiable information</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub content_identification_type: ::std::option::Option<crate::types::ContentType>,
    /// <p>Redacts all personally identifiable information (PII) identified in your transcript.</p>
    /// <p>Content redaction is performed at the segment level; PII specified in PiiEntityTypes is redacted upon complete transcription of an audio segment.</p>
    /// <p>You can’t set ContentRedactionType and ContentIdentificationType in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction.html">Redacting or identifying personally identifiable information</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub content_redaction_type: ::std::option::Option<crate::types::ContentType>,
    /// <p>The types of personally identifiable information (PII) to redact from a transcript. You can include as many types as you'd like, or you can select <code>ALL</code>.</p>
    /// <p>To include <code>PiiEntityTypes</code> in your Call Analytics request, you must also include <code>ContentIdentificationType</code> or <code>ContentRedactionType</code>, but you can't include both.</p>
    /// <p>Values must be comma-separated and can include: <code>ADDRESS</code>, <code>BANK_ACCOUNT_NUMBER</code>, <code>BANK_ROUTING</code>, <code>CREDIT_DEBIT_CVV</code>, <code>CREDIT_DEBIT_EXPIRY</code>, <code>CREDIT_DEBIT_NUMBER</code>, <code>EMAIL</code>, <code>NAME</code>, <code>PHONE</code>, <code>PIN</code>, <code>SSN</code>, or <code>ALL</code>.</p>
    /// <p>If you leave this parameter empty, the default behavior is equivalent to <code>ALL</code>.</p>
    pub pii_entity_types: ::std::option::Option<::std::string::String>,
    /// <p>The name of the custom language model that you want to use when processing your transcription. Note that language model names are case sensitive.</p>
    /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the custom language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/custom-language-models.html">Custom language models</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub language_model_name: ::std::option::Option<::std::string::String>,
    /// <p>If true, <code>TranscriptEvents</code> with <code>IsPartial: true</code> are filtered out of the insights target.</p>
    pub filter_partial_results: bool,
    /// <p>Turns language identification on or off.</p>
    pub identify_language: bool,
    /// <p>The language options for the transcription, such as automatic language detection.</p>
    pub language_options: ::std::option::Option<::std::string::String>,
    /// <p>The preferred language for the transcription.</p>
    pub preferred_language: ::std::option::Option<crate::types::CallAnalyticsLanguageCode>,
    /// <p>The names of the custom vocabulary or vocabularies used during transcription.</p>
    pub vocabulary_names: ::std::option::Option<::std::string::String>,
    /// <p>The names of the custom vocabulary filter or filters using during transcription.</p>
    pub vocabulary_filter_names: ::std::option::Option<::std::string::String>,
}
impl AmazonTranscribeProcessorConfiguration {
    /// <p>The language code that represents the language spoken in your audio.</p>
    /// <p>If you're unsure of the language spoken in your audio, consider using <code>IdentifyLanguage</code> to enable automatic language identification.</p>
    /// <p>For a list of languages that real-time Call Analytics supports, see the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages table</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn language_code(&self) -> ::std::option::Option<&crate::types::CallAnalyticsLanguageCode> {
        self.language_code.as_ref()
    }
    /// <p>The name of the custom vocabulary that you specified in your Call Analytics request.</p>
    /// <p>Length Constraints: Minimum length of 1. Maximum length of 200.</p>
    pub fn vocabulary_name(&self) -> ::std::option::Option<&str> {
        self.vocabulary_name.as_deref()
    }
    /// <p>The name of the custom vocabulary filter that you specified in your Call Analytics request.</p>
    /// <p>Length Constraints: Minimum length of 1. Maximum length of 200.</p>
    pub fn vocabulary_filter_name(&self) -> ::std::option::Option<&str> {
        self.vocabulary_filter_name.as_deref()
    }
    /// <p>The vocabulary filtering method used in your Call Analytics transcription.</p>
    pub fn vocabulary_filter_method(&self) -> ::std::option::Option<&crate::types::VocabularyFilterMethod> {
        self.vocabulary_filter_method.as_ref()
    }
    /// <p>Enables speaker partitioning (diarization) in your transcription output. Speaker partitioning labels the speech from individual speakers in your media file.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/diarization.html">Partitioning speakers (diarization)</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn show_speaker_label(&self) -> bool {
        self.show_speaker_label
    }
    /// <p>Enables partial result stabilization for your transcription. Partial result stabilization can reduce latency in your output, but may impact accuracy.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html#streaming-partial-result-stabilization">Partial-result stabilization</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn enable_partial_results_stabilization(&self) -> bool {
        self.enable_partial_results_stabilization
    }
    /// <p>The level of stability to use when you enable partial results stabilization (<code>EnablePartialResultsStabilization</code>).</p>
    /// <p>Low stability provides the highest accuracy. High stability transcribes faster, but with slightly lower accuracy.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html#streaming-partial-result-stabilization">Partial-result stabilization</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn partial_results_stability(&self) -> ::std::option::Option<&crate::types::PartialResultsStability> {
        self.partial_results_stability.as_ref()
    }
    /// <p>Labels all personally identifiable information (PII) identified in your transcript.</p>
    /// <p>Content identification is performed at the segment level; PII specified in <code>PiiEntityTypes</code> is flagged upon complete transcription of an audio segment.</p>
    /// <p>You can’t set <code>ContentIdentificationType</code> and <code>ContentRedactionType</code> in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction.html">Redacting or identifying personally identifiable information</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn content_identification_type(&self) -> ::std::option::Option<&crate::types::ContentType> {
        self.content_identification_type.as_ref()
    }
    /// <p>Redacts all personally identifiable information (PII) identified in your transcript.</p>
    /// <p>Content redaction is performed at the segment level; PII specified in PiiEntityTypes is redacted upon complete transcription of an audio segment.</p>
    /// <p>You can’t set ContentRedactionType and ContentIdentificationType in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction.html">Redacting or identifying personally identifiable information</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn content_redaction_type(&self) -> ::std::option::Option<&crate::types::ContentType> {
        self.content_redaction_type.as_ref()
    }
    /// <p>The types of personally identifiable information (PII) to redact from a transcript. You can include as many types as you'd like, or you can select <code>ALL</code>.</p>
    /// <p>To include <code>PiiEntityTypes</code> in your Call Analytics request, you must also include <code>ContentIdentificationType</code> or <code>ContentRedactionType</code>, but you can't include both.</p>
    /// <p>Values must be comma-separated and can include: <code>ADDRESS</code>, <code>BANK_ACCOUNT_NUMBER</code>, <code>BANK_ROUTING</code>, <code>CREDIT_DEBIT_CVV</code>, <code>CREDIT_DEBIT_EXPIRY</code>, <code>CREDIT_DEBIT_NUMBER</code>, <code>EMAIL</code>, <code>NAME</code>, <code>PHONE</code>, <code>PIN</code>, <code>SSN</code>, or <code>ALL</code>.</p>
    /// <p>If you leave this parameter empty, the default behavior is equivalent to <code>ALL</code>.</p>
    pub fn pii_entity_types(&self) -> ::std::option::Option<&str> {
        self.pii_entity_types.as_deref()
    }
    /// <p>The name of the custom language model that you want to use when processing your transcription. Note that language model names are case sensitive.</p>
    /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the custom language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/custom-language-models.html">Custom language models</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn language_model_name(&self) -> ::std::option::Option<&str> {
        self.language_model_name.as_deref()
    }
    /// <p>If true, <code>TranscriptEvents</code> with <code>IsPartial: true</code> are filtered out of the insights target.</p>
    pub fn filter_partial_results(&self) -> bool {
        self.filter_partial_results
    }
    /// <p>Turns language identification on or off.</p>
    pub fn identify_language(&self) -> bool {
        self.identify_language
    }
    /// <p>The language options for the transcription, such as automatic language detection.</p>
    pub fn language_options(&self) -> ::std::option::Option<&str> {
        self.language_options.as_deref()
    }
    /// <p>The preferred language for the transcription.</p>
    pub fn preferred_language(&self) -> ::std::option::Option<&crate::types::CallAnalyticsLanguageCode> {
        self.preferred_language.as_ref()
    }
    /// <p>The names of the custom vocabulary or vocabularies used during transcription.</p>
    pub fn vocabulary_names(&self) -> ::std::option::Option<&str> {
        self.vocabulary_names.as_deref()
    }
    /// <p>The names of the custom vocabulary filter or filters using during transcription.</p>
    pub fn vocabulary_filter_names(&self) -> ::std::option::Option<&str> {
        self.vocabulary_filter_names.as_deref()
    }
}
impl AmazonTranscribeProcessorConfiguration {
    /// Creates a new builder-style object to manufacture [`AmazonTranscribeProcessorConfiguration`](crate::types::AmazonTranscribeProcessorConfiguration).
    pub fn builder() -> crate::types::builders::AmazonTranscribeProcessorConfigurationBuilder {
        crate::types::builders::AmazonTranscribeProcessorConfigurationBuilder::default()
    }
}

/// A builder for [`AmazonTranscribeProcessorConfiguration`](crate::types::AmazonTranscribeProcessorConfiguration).
#[non_exhaustive]
#[derive(::std::clone::Clone, ::std::cmp::PartialEq, ::std::default::Default, ::std::fmt::Debug)]
pub struct AmazonTranscribeProcessorConfigurationBuilder {
    pub(crate) language_code: ::std::option::Option<crate::types::CallAnalyticsLanguageCode>,
    pub(crate) vocabulary_name: ::std::option::Option<::std::string::String>,
    pub(crate) vocabulary_filter_name: ::std::option::Option<::std::string::String>,
    pub(crate) vocabulary_filter_method: ::std::option::Option<crate::types::VocabularyFilterMethod>,
    pub(crate) show_speaker_label: ::std::option::Option<bool>,
    pub(crate) enable_partial_results_stabilization: ::std::option::Option<bool>,
    pub(crate) partial_results_stability: ::std::option::Option<crate::types::PartialResultsStability>,
    pub(crate) content_identification_type: ::std::option::Option<crate::types::ContentType>,
    pub(crate) content_redaction_type: ::std::option::Option<crate::types::ContentType>,
    pub(crate) pii_entity_types: ::std::option::Option<::std::string::String>,
    pub(crate) language_model_name: ::std::option::Option<::std::string::String>,
    pub(crate) filter_partial_results: ::std::option::Option<bool>,
    pub(crate) identify_language: ::std::option::Option<bool>,
    pub(crate) language_options: ::std::option::Option<::std::string::String>,
    pub(crate) preferred_language: ::std::option::Option<crate::types::CallAnalyticsLanguageCode>,
    pub(crate) vocabulary_names: ::std::option::Option<::std::string::String>,
    pub(crate) vocabulary_filter_names: ::std::option::Option<::std::string::String>,
}
impl AmazonTranscribeProcessorConfigurationBuilder {
    /// <p>The language code that represents the language spoken in your audio.</p>
    /// <p>If you're unsure of the language spoken in your audio, consider using <code>IdentifyLanguage</code> to enable automatic language identification.</p>
    /// <p>For a list of languages that real-time Call Analytics supports, see the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages table</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn language_code(mut self, input: crate::types::CallAnalyticsLanguageCode) -> Self {
        self.language_code = ::std::option::Option::Some(input);
        self
    }
    /// <p>The language code that represents the language spoken in your audio.</p>
    /// <p>If you're unsure of the language spoken in your audio, consider using <code>IdentifyLanguage</code> to enable automatic language identification.</p>
    /// <p>For a list of languages that real-time Call Analytics supports, see the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages table</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn set_language_code(mut self, input: ::std::option::Option<crate::types::CallAnalyticsLanguageCode>) -> Self {
        self.language_code = input;
        self
    }
    /// <p>The language code that represents the language spoken in your audio.</p>
    /// <p>If you're unsure of the language spoken in your audio, consider using <code>IdentifyLanguage</code> to enable automatic language identification.</p>
    /// <p>For a list of languages that real-time Call Analytics supports, see the <a href="https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html">Supported languages table</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn get_language_code(&self) -> &::std::option::Option<crate::types::CallAnalyticsLanguageCode> {
        &self.language_code
    }
    /// <p>The name of the custom vocabulary that you specified in your Call Analytics request.</p>
    /// <p>Length Constraints: Minimum length of 1. Maximum length of 200.</p>
    pub fn vocabulary_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.vocabulary_name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The name of the custom vocabulary that you specified in your Call Analytics request.</p>
    /// <p>Length Constraints: Minimum length of 1. Maximum length of 200.</p>
    pub fn set_vocabulary_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.vocabulary_name = input;
        self
    }
    /// <p>The name of the custom vocabulary that you specified in your Call Analytics request.</p>
    /// <p>Length Constraints: Minimum length of 1. Maximum length of 200.</p>
    pub fn get_vocabulary_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.vocabulary_name
    }
    /// <p>The name of the custom vocabulary filter that you specified in your Call Analytics request.</p>
    /// <p>Length Constraints: Minimum length of 1. Maximum length of 200.</p>
    pub fn vocabulary_filter_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.vocabulary_filter_name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The name of the custom vocabulary filter that you specified in your Call Analytics request.</p>
    /// <p>Length Constraints: Minimum length of 1. Maximum length of 200.</p>
    pub fn set_vocabulary_filter_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.vocabulary_filter_name = input;
        self
    }
    /// <p>The name of the custom vocabulary filter that you specified in your Call Analytics request.</p>
    /// <p>Length Constraints: Minimum length of 1. Maximum length of 200.</p>
    pub fn get_vocabulary_filter_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.vocabulary_filter_name
    }
    /// <p>The vocabulary filtering method used in your Call Analytics transcription.</p>
    pub fn vocabulary_filter_method(mut self, input: crate::types::VocabularyFilterMethod) -> Self {
        self.vocabulary_filter_method = ::std::option::Option::Some(input);
        self
    }
    /// <p>The vocabulary filtering method used in your Call Analytics transcription.</p>
    pub fn set_vocabulary_filter_method(mut self, input: ::std::option::Option<crate::types::VocabularyFilterMethod>) -> Self {
        self.vocabulary_filter_method = input;
        self
    }
    /// <p>The vocabulary filtering method used in your Call Analytics transcription.</p>
    pub fn get_vocabulary_filter_method(&self) -> &::std::option::Option<crate::types::VocabularyFilterMethod> {
        &self.vocabulary_filter_method
    }
    /// <p>Enables speaker partitioning (diarization) in your transcription output. Speaker partitioning labels the speech from individual speakers in your media file.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/diarization.html">Partitioning speakers (diarization)</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn show_speaker_label(mut self, input: bool) -> Self {
        self.show_speaker_label = ::std::option::Option::Some(input);
        self
    }
    /// <p>Enables speaker partitioning (diarization) in your transcription output. Speaker partitioning labels the speech from individual speakers in your media file.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/diarization.html">Partitioning speakers (diarization)</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn set_show_speaker_label(mut self, input: ::std::option::Option<bool>) -> Self {
        self.show_speaker_label = input;
        self
    }
    /// <p>Enables speaker partitioning (diarization) in your transcription output. Speaker partitioning labels the speech from individual speakers in your media file.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/diarization.html">Partitioning speakers (diarization)</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn get_show_speaker_label(&self) -> &::std::option::Option<bool> {
        &self.show_speaker_label
    }
    /// <p>Enables partial result stabilization for your transcription. Partial result stabilization can reduce latency in your output, but may impact accuracy.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html#streaming-partial-result-stabilization">Partial-result stabilization</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn enable_partial_results_stabilization(mut self, input: bool) -> Self {
        self.enable_partial_results_stabilization = ::std::option::Option::Some(input);
        self
    }
    /// <p>Enables partial result stabilization for your transcription. Partial result stabilization can reduce latency in your output, but may impact accuracy.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html#streaming-partial-result-stabilization">Partial-result stabilization</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn set_enable_partial_results_stabilization(mut self, input: ::std::option::Option<bool>) -> Self {
        self.enable_partial_results_stabilization = input;
        self
    }
    /// <p>Enables partial result stabilization for your transcription. Partial result stabilization can reduce latency in your output, but may impact accuracy.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html#streaming-partial-result-stabilization">Partial-result stabilization</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn get_enable_partial_results_stabilization(&self) -> &::std::option::Option<bool> {
        &self.enable_partial_results_stabilization
    }
    /// <p>The level of stability to use when you enable partial results stabilization (<code>EnablePartialResultsStabilization</code>).</p>
    /// <p>Low stability provides the highest accuracy. High stability transcribes faster, but with slightly lower accuracy.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html#streaming-partial-result-stabilization">Partial-result stabilization</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn partial_results_stability(mut self, input: crate::types::PartialResultsStability) -> Self {
        self.partial_results_stability = ::std::option::Option::Some(input);
        self
    }
    /// <p>The level of stability to use when you enable partial results stabilization (<code>EnablePartialResultsStabilization</code>).</p>
    /// <p>Low stability provides the highest accuracy. High stability transcribes faster, but with slightly lower accuracy.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html#streaming-partial-result-stabilization">Partial-result stabilization</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn set_partial_results_stability(mut self, input: ::std::option::Option<crate::types::PartialResultsStability>) -> Self {
        self.partial_results_stability = input;
        self
    }
    /// <p>The level of stability to use when you enable partial results stabilization (<code>EnablePartialResultsStabilization</code>).</p>
    /// <p>Low stability provides the highest accuracy. High stability transcribes faster, but with slightly lower accuracy.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html#streaming-partial-result-stabilization">Partial-result stabilization</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn get_partial_results_stability(&self) -> &::std::option::Option<crate::types::PartialResultsStability> {
        &self.partial_results_stability
    }
    /// <p>Labels all personally identifiable information (PII) identified in your transcript.</p>
    /// <p>Content identification is performed at the segment level; PII specified in <code>PiiEntityTypes</code> is flagged upon complete transcription of an audio segment.</p>
    /// <p>You can’t set <code>ContentIdentificationType</code> and <code>ContentRedactionType</code> in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction.html">Redacting or identifying personally identifiable information</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn content_identification_type(mut self, input: crate::types::ContentType) -> Self {
        self.content_identification_type = ::std::option::Option::Some(input);
        self
    }
    /// <p>Labels all personally identifiable information (PII) identified in your transcript.</p>
    /// <p>Content identification is performed at the segment level; PII specified in <code>PiiEntityTypes</code> is flagged upon complete transcription of an audio segment.</p>
    /// <p>You can’t set <code>ContentIdentificationType</code> and <code>ContentRedactionType</code> in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction.html">Redacting or identifying personally identifiable information</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn set_content_identification_type(mut self, input: ::std::option::Option<crate::types::ContentType>) -> Self {
        self.content_identification_type = input;
        self
    }
    /// <p>Labels all personally identifiable information (PII) identified in your transcript.</p>
    /// <p>Content identification is performed at the segment level; PII specified in <code>PiiEntityTypes</code> is flagged upon complete transcription of an audio segment.</p>
    /// <p>You can’t set <code>ContentIdentificationType</code> and <code>ContentRedactionType</code> in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction.html">Redacting or identifying personally identifiable information</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn get_content_identification_type(&self) -> &::std::option::Option<crate::types::ContentType> {
        &self.content_identification_type
    }
    /// <p>Redacts all personally identifiable information (PII) identified in your transcript.</p>
    /// <p>Content redaction is performed at the segment level; PII specified in PiiEntityTypes is redacted upon complete transcription of an audio segment.</p>
    /// <p>You can’t set ContentRedactionType and ContentIdentificationType in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction.html">Redacting or identifying personally identifiable information</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn content_redaction_type(mut self, input: crate::types::ContentType) -> Self {
        self.content_redaction_type = ::std::option::Option::Some(input);
        self
    }
    /// <p>Redacts all personally identifiable information (PII) identified in your transcript.</p>
    /// <p>Content redaction is performed at the segment level; PII specified in PiiEntityTypes is redacted upon complete transcription of an audio segment.</p>
    /// <p>You can’t set ContentRedactionType and ContentIdentificationType in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction.html">Redacting or identifying personally identifiable information</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn set_content_redaction_type(mut self, input: ::std::option::Option<crate::types::ContentType>) -> Self {
        self.content_redaction_type = input;
        self
    }
    /// <p>Redacts all personally identifiable information (PII) identified in your transcript.</p>
    /// <p>Content redaction is performed at the segment level; PII specified in PiiEntityTypes is redacted upon complete transcription of an audio segment.</p>
    /// <p>You can’t set ContentRedactionType and ContentIdentificationType in the same request. If you set both, your request returns a <code>BadRequestException</code>.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction.html">Redacting or identifying personally identifiable information</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn get_content_redaction_type(&self) -> &::std::option::Option<crate::types::ContentType> {
        &self.content_redaction_type
    }
    /// <p>The types of personally identifiable information (PII) to redact from a transcript. You can include as many types as you'd like, or you can select <code>ALL</code>.</p>
    /// <p>To include <code>PiiEntityTypes</code> in your Call Analytics request, you must also include <code>ContentIdentificationType</code> or <code>ContentRedactionType</code>, but you can't include both.</p>
    /// <p>Values must be comma-separated and can include: <code>ADDRESS</code>, <code>BANK_ACCOUNT_NUMBER</code>, <code>BANK_ROUTING</code>, <code>CREDIT_DEBIT_CVV</code>, <code>CREDIT_DEBIT_EXPIRY</code>, <code>CREDIT_DEBIT_NUMBER</code>, <code>EMAIL</code>, <code>NAME</code>, <code>PHONE</code>, <code>PIN</code>, <code>SSN</code>, or <code>ALL</code>.</p>
    /// <p>If you leave this parameter empty, the default behavior is equivalent to <code>ALL</code>.</p>
    pub fn pii_entity_types(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.pii_entity_types = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The types of personally identifiable information (PII) to redact from a transcript. You can include as many types as you'd like, or you can select <code>ALL</code>.</p>
    /// <p>To include <code>PiiEntityTypes</code> in your Call Analytics request, you must also include <code>ContentIdentificationType</code> or <code>ContentRedactionType</code>, but you can't include both.</p>
    /// <p>Values must be comma-separated and can include: <code>ADDRESS</code>, <code>BANK_ACCOUNT_NUMBER</code>, <code>BANK_ROUTING</code>, <code>CREDIT_DEBIT_CVV</code>, <code>CREDIT_DEBIT_EXPIRY</code>, <code>CREDIT_DEBIT_NUMBER</code>, <code>EMAIL</code>, <code>NAME</code>, <code>PHONE</code>, <code>PIN</code>, <code>SSN</code>, or <code>ALL</code>.</p>
    /// <p>If you leave this parameter empty, the default behavior is equivalent to <code>ALL</code>.</p>
    pub fn set_pii_entity_types(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.pii_entity_types = input;
        self
    }
    /// <p>The types of personally identifiable information (PII) to redact from a transcript. You can include as many types as you'd like, or you can select <code>ALL</code>.</p>
    /// <p>To include <code>PiiEntityTypes</code> in your Call Analytics request, you must also include <code>ContentIdentificationType</code> or <code>ContentRedactionType</code>, but you can't include both.</p>
    /// <p>Values must be comma-separated and can include: <code>ADDRESS</code>, <code>BANK_ACCOUNT_NUMBER</code>, <code>BANK_ROUTING</code>, <code>CREDIT_DEBIT_CVV</code>, <code>CREDIT_DEBIT_EXPIRY</code>, <code>CREDIT_DEBIT_NUMBER</code>, <code>EMAIL</code>, <code>NAME</code>, <code>PHONE</code>, <code>PIN</code>, <code>SSN</code>, or <code>ALL</code>.</p>
    /// <p>If you leave this parameter empty, the default behavior is equivalent to <code>ALL</code>.</p>
    pub fn get_pii_entity_types(&self) -> &::std::option::Option<::std::string::String> {
        &self.pii_entity_types
    }
    /// <p>The name of the custom language model that you want to use when processing your transcription. Note that language model names are case sensitive.</p>
    /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the custom language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/custom-language-models.html">Custom language models</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn language_model_name(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.language_model_name = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The name of the custom language model that you want to use when processing your transcription. Note that language model names are case sensitive.</p>
    /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the custom language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/custom-language-models.html">Custom language models</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn set_language_model_name(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.language_model_name = input;
        self
    }
    /// <p>The name of the custom language model that you want to use when processing your transcription. Note that language model names are case sensitive.</p>
    /// <p>The language of the specified language model must match the language code you specify in your transcription request. If the languages don't match, the custom language model isn't applied. There are no errors or warnings associated with a language mismatch.</p>
    /// <p>For more information, see <a href="https://docs.aws.amazon.com/transcribe/latest/dg/custom-language-models.html">Custom language models</a> in the <i>Amazon Transcribe Developer Guide</i>.</p>
    pub fn get_language_model_name(&self) -> &::std::option::Option<::std::string::String> {
        &self.language_model_name
    }
    /// <p>If true, <code>TranscriptEvents</code> with <code>IsPartial: true</code> are filtered out of the insights target.</p>
    pub fn filter_partial_results(mut self, input: bool) -> Self {
        self.filter_partial_results = ::std::option::Option::Some(input);
        self
    }
    /// <p>If true, <code>TranscriptEvents</code> with <code>IsPartial: true</code> are filtered out of the insights target.</p>
    pub fn set_filter_partial_results(mut self, input: ::std::option::Option<bool>) -> Self {
        self.filter_partial_results = input;
        self
    }
    /// <p>If true, <code>TranscriptEvents</code> with <code>IsPartial: true</code> are filtered out of the insights target.</p>
    pub fn get_filter_partial_results(&self) -> &::std::option::Option<bool> {
        &self.filter_partial_results
    }
    /// <p>Turns language identification on or off.</p>
    pub fn identify_language(mut self, input: bool) -> Self {
        self.identify_language = ::std::option::Option::Some(input);
        self
    }
    /// <p>Turns language identification on or off.</p>
    pub fn set_identify_language(mut self, input: ::std::option::Option<bool>) -> Self {
        self.identify_language = input;
        self
    }
    /// <p>Turns language identification on or off.</p>
    pub fn get_identify_language(&self) -> &::std::option::Option<bool> {
        &self.identify_language
    }
    /// <p>The language options for the transcription, such as automatic language detection.</p>
    pub fn language_options(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.language_options = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The language options for the transcription, such as automatic language detection.</p>
    pub fn set_language_options(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.language_options = input;
        self
    }
    /// <p>The language options for the transcription, such as automatic language detection.</p>
    pub fn get_language_options(&self) -> &::std::option::Option<::std::string::String> {
        &self.language_options
    }
    /// <p>The preferred language for the transcription.</p>
    pub fn preferred_language(mut self, input: crate::types::CallAnalyticsLanguageCode) -> Self {
        self.preferred_language = ::std::option::Option::Some(input);
        self
    }
    /// <p>The preferred language for the transcription.</p>
    pub fn set_preferred_language(mut self, input: ::std::option::Option<crate::types::CallAnalyticsLanguageCode>) -> Self {
        self.preferred_language = input;
        self
    }
    /// <p>The preferred language for the transcription.</p>
    pub fn get_preferred_language(&self) -> &::std::option::Option<crate::types::CallAnalyticsLanguageCode> {
        &self.preferred_language
    }
    /// <p>The names of the custom vocabulary or vocabularies used during transcription.</p>
    pub fn vocabulary_names(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.vocabulary_names = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The names of the custom vocabulary or vocabularies used during transcription.</p>
    pub fn set_vocabulary_names(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.vocabulary_names = input;
        self
    }
    /// <p>The names of the custom vocabulary or vocabularies used during transcription.</p>
    pub fn get_vocabulary_names(&self) -> &::std::option::Option<::std::string::String> {
        &self.vocabulary_names
    }
    /// <p>The names of the custom vocabulary filter or filters using during transcription.</p>
    pub fn vocabulary_filter_names(mut self, input: impl ::std::convert::Into<::std::string::String>) -> Self {
        self.vocabulary_filter_names = ::std::option::Option::Some(input.into());
        self
    }
    /// <p>The names of the custom vocabulary filter or filters using during transcription.</p>
    pub fn set_vocabulary_filter_names(mut self, input: ::std::option::Option<::std::string::String>) -> Self {
        self.vocabulary_filter_names = input;
        self
    }
    /// <p>The names of the custom vocabulary filter or filters using during transcription.</p>
    pub fn get_vocabulary_filter_names(&self) -> &::std::option::Option<::std::string::String> {
        &self.vocabulary_filter_names
    }
    /// Consumes the builder and constructs a [`AmazonTranscribeProcessorConfiguration`](crate::types::AmazonTranscribeProcessorConfiguration).
    pub fn build(self) -> crate::types::AmazonTranscribeProcessorConfiguration {
        crate::types::AmazonTranscribeProcessorConfiguration {
            language_code: self.language_code,
            vocabulary_name: self.vocabulary_name,
            vocabulary_filter_name: self.vocabulary_filter_name,
            vocabulary_filter_method: self.vocabulary_filter_method,
            show_speaker_label: self.show_speaker_label.unwrap_or_default(),
            enable_partial_results_stabilization: self.enable_partial_results_stabilization.unwrap_or_default(),
            partial_results_stability: self.partial_results_stability,
            content_identification_type: self.content_identification_type,
            content_redaction_type: self.content_redaction_type,
            pii_entity_types: self.pii_entity_types,
            language_model_name: self.language_model_name,
            filter_partial_results: self.filter_partial_results.unwrap_or_default(),
            identify_language: self.identify_language.unwrap_or_default(),
            language_options: self.language_options,
            preferred_language: self.preferred_language,
            vocabulary_names: self.vocabulary_names,
            vocabulary_filter_names: self.vocabulary_filter_names,
        }
    }
}
